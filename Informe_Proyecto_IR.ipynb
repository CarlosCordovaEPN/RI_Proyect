{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Primer Bimestre - Reuters\n",
    "### Integrantes\n",
    "- Carlos Córdova\n",
    "- Hernán Sánchez\n",
    "- Galo Tarapués"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción \n",
    "\n",
    "El presente proyecto implementa un **sistema de recuperación de información** , diseñado para trabajar con el corpus *Reuters-21578*. \n",
    "\n",
    "El objetivo principal del proyecto es **es diseñar, construir, programar y desplegar un Sistema de Recuperación de Información (SRI) utilizando el corpus Reuters-21578**. \n",
    "\n",
    "## Fases del proyecto \n",
    "\n",
    "El sistema se divide en varias fases interconectadas. Estas incluyen:\n",
    "\n",
    "1. **Adquisición de los Datos**\n",
    "2. **Preprocesamiento del corpus**\n",
    "3. **Representación de Datos en Espacio Vectorial**\n",
    "4. **Indexación**\n",
    "5. **Mecanismo de búsqueda**\n",
    "6. **Evaluación del sistema**\n",
    "\n",
    "Los cuales seran detallados a continuación: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Adquisición de los Datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Carga de documentos: \n",
    "\n",
    "Los documentos se cargan desde una carpeta especifica del directorio del proyecto, que contiene noticias etiquetadas con categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from typing import List, Dict\n",
    "\n",
    "# Configuración de logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_documents(directory_path: str) -> List[Dict]:\n",
    "    \n",
    "    documents = []\n",
    "    for root, _, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.sgm'):  # Aseguramos que solo se procesen archivos SGML\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                        content = f.read()\n",
    "                    documents.append({'file_name': file, 'content': content})  # Guardamos el contenido\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error leyendo {file_path}: {e}\")\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocesamiento del corpus \n",
    "\n",
    "1. Librerias usadas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Permite operaciones con rutas y archivos del sistema.\n",
    "import re # Facilita la manipulación y limpieza de texto mediante expresiones regulares.\n",
    "import nltk # Ofrece herramientas avanzadas de NLP como tokenización y manejo de stopwords.\n",
    "import pandas as pd # Estructura los datos en un formato tabular para facilitar el análisis.\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "import logging # Registra eventos y errores para depuración y análisis posterior.\n",
    "\n",
    "# Configuración de logs\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Extracción de Contenido Relevante\n",
    "\n",
    "Cada documento es convertido en un diccionario con los siguientes campos:\n",
    "\n",
    "- id: Identificador único del documento (nombre del archivo).\n",
    "- title: Título procesado.\n",
    "- body: Cuerpo del texto procesado.\n",
    "- categories: Lista de etiquetas asociadas al documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(self, file_path: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Procesa un documento en bruto y extrae los campos relevantes.\n",
    "    Args:\n",
    "        file_path (str): Ruta del archivo del documento.\n",
    "    Returns:\n",
    "        Dict: Diccionario con 'id', 'title', 'body' y 'categories'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Leer el documento\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Separar título y cuerpo\n",
    "        parts = content.split(\"\\n\", 1)\n",
    "        title = parts[0] if len(parts) > 0 else \"\"\n",
    "        body = parts[1] if len(parts) > 1 else \"\"\n",
    "        \n",
    "        # Obtener nombre del archivo como ID del documento\n",
    "        doc_id = os.path.basename(file_path)\n",
    "        \n",
    "        # Asociar categorías desde el archivo externo\n",
    "        categories = self.categories.get(doc_id, [])\n",
    "        \n",
    "        return {\n",
    "            'id': doc_id,\n",
    "            'title': title.strip(),\n",
    "            'body': body.strip(),\n",
    "            'categories': categories\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error procesando documento {file_path}: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Limpieza del texto\n",
    "\n",
    "El texto obtenido se limpia para eliminar caracteres no deseados, etiquetas HTML, y otros elementos residuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Limpia el texto eliminando etiquetas HTML, caracteres no alfabéticos y normalizando.\n",
    "    Args:\n",
    "        text (str): Texto original.\n",
    "    Returns:\n",
    "        str: Texto limpio.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'<[^>]+>', '', text)  # Elimina etiquetas HTML\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Sustituye caracteres no alfabéticos\n",
    "    text = text.lower()  # Convierte a minúsculas\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Tokenización\n",
    "\n",
    "- La función tokenize_text utiliza la función word_tokenize para dividir el texto limpio en tokens.\n",
    "- Los tokens son devueltos como una lista de cadenas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize_text(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Divide el texto en palabras individuales.\n",
    "    Args:\n",
    "        text (str): Texto limpio.\n",
    "    Returns:\n",
    "        list: Lista de palabras (tokens).\n",
    "    \"\"\"\n",
    "    return word_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Filtrado de stopwords\n",
    "\n",
    "Las palabras stopwords son eliminadas en lo siguientes pasos:\n",
    "\n",
    "- Primero se descarga el conjunto de stopwords en inglés de la librería nltk.\n",
    "- La función remove_stopwords toma una lista de tokens y se compara con la lista de stopwords y se descarta si coincide.\n",
    "- Devuelve una lista de tokens filtrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(tokens: list, stopword_path: str) -> list:\n",
    "    \"\"\"\n",
    "    Filtra palabras vacías de los tokens.\n",
    "    Args:\n",
    "        tokens (list): Lista de palabras tokenizadas.\n",
    "        stopword_path (str): Ruta al archivo de stopwords personalizadas.\n",
    "    Returns:\n",
    "        list: Lista de tokens sin stopwords.\n",
    "    \"\"\"\n",
    "    with open(stopword_path, 'r') as f:\n",
    "        custom_stopwords = set(f.read().splitlines())\n",
    "    all_stopwords = custom_stopwords.union(set(stopwords.words('english')))\n",
    "    return [word for word in tokens if word not in all_stopwords]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Lematización\n",
    "\n",
    "- Se descarga el recurso wordnet de nltk para usar el lematizador.\n",
    "- La función lemmatize_tokens toma la lista de tokens y aplica la lematización a cada uno, devolviendo una lista con las palabras lematizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tokens(tokens: list) -> list:\n",
    "    \"\"\"\n",
    "    Aplica lematización a los tokens.\n",
    "    Args:\n",
    "        tokens (list): Lista de tokens filtrados.\n",
    "    Returns:\n",
    "        list: Lista de tokens lematizados.\n",
    "    \"\"\"\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Normalizacion\n",
    "\n",
    "- Se utilizar un diccionario de normalización con términos comunes en noticias Reuters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_normalization_dict(self) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Carga el diccionario \n",
    "        \"\"\"\n",
    "        return {\n",
    "            # Countries and Regions\n",
    "            'uk': 'united kingdom',\n",
    "            'britain': 'united kingdom',\n",
    "            'great britain': 'united kingdom',\n",
    "            'united kingdom': 'united kingdom',\n",
    "            'england': 'united kingdom',\n",
    "            'british': 'united kingdom',\n",
    "            'us': 'united states',\n",
    "            'usa': 'united states',\n",
    "            'united states of america': 'united states',\n",
    "            'united states': 'united states',\n",
    "            'america': 'united states',\n",
    "            'american': 'united states',\n",
    "            \n",
    "            # Organizational Entities\n",
    "            'un': 'united nations',\n",
    "            'united nations': 'united nations',\n",
    "            'who': 'world health organization',\n",
    "            'world health organization': 'world health organization',\n",
    "            'imf': 'international monetary fund',\n",
    "            'international monetary fund': 'international monetary fund',\n",
    "            'wb': 'world bank',\n",
    "            'world bank': 'world bank',\n",
    "            'wto': 'world trade organization',\n",
    "            'world trade organization': 'world trade organization',\n",
    "            'nato': 'north atlantic treaty organization',\n",
    "            'north atlantic treaty organization': 'north atlantic treaty organization',\n",
    "            \n",
    "            # Financial Markets\n",
    "            'nyse': 'new york stock exchange',\n",
    "            'nasdaq': 'nasdaq stock market',\n",
    "            'djia': 'dow jones industrial average',\n",
    "            'sp500': 'standard and poors 500',\n",
    "            's&p': 'standard and poors 500',\n",
    "            'ftse': 'financial times stock exchange',\n",
    "            \n",
    "            # Central Banks\n",
    "            'fed': 'federal reserve',\n",
    "            'federal reserve': 'federal reserve',\n",
    "            'ecb': 'european central bank',\n",
    "            'boe': 'bank of england',\n",
    "            'pboc': 'peoples bank of china',\n",
    "            'boj': 'bank of japan',\n",
    "            \n",
    "            # Economic Indicators\n",
    "            'gdp': 'gross domestic product',\n",
    "            'cpi': 'consumer price index',\n",
    "            'ppi': 'producer price index',\n",
    "            'pmi': 'purchasing managers index',\n",
    "            'ism': 'institute supply management',\n",
    "            'nfp': 'non farm payrolls',\n",
    "            \n",
    "            # Business Terms\n",
    "            'ceo': 'chief executive officer',\n",
    "            'cfo': 'chief financial officer',\n",
    "            'coo': 'chief operating officer',\n",
    "            'ipo': 'initial public offering',\n",
    "            'ma': 'mergers acquisitions',\n",
    "            'eps': 'earnings per share',\n",
    "            'ebit': 'earnings before interest taxes',\n",
    "            'ebitda': 'earnings before interest taxes depreciation amortization',\n",
    "            \n",
    "            # Commodities\n",
    "            'wti': 'west texas intermediate',\n",
    "            'brent': 'brent crude oil',\n",
    "            'opec': 'organization petroleum exporting countries',\n",
    "            'lng': 'liquefied natural gas',\n",
    "            \n",
    "            # Technology\n",
    "            'ai': 'artificial intelligence',\n",
    "            'ml': 'machine learning',\n",
    "            'iot': 'internet of things',\n",
    "            'saas': 'software as service',\n",
    "            'paas': 'platform as service',\n",
    "            'iaas': 'infrastructure as service',\n",
    "            \n",
    "            # Market Terms\n",
    "            'ytd': 'year to date',\n",
    "            'yoy': 'year over year',\n",
    "            'qoq': 'quarter over quarter',\n",
    "            'mom': 'month over month',\n",
    "            'ttm': 'trailing twelve months',\n",
    "            \n",
    "            # Time Zones\n",
    "            'est': 'eastern standard time',\n",
    "            'edt': 'eastern daylight time',\n",
    "            'gmt': 'greenwich mean time',\n",
    "            'utc': 'coordinated universal time',\n",
    "            \n",
    "            # Common Industry Terms\n",
    "            'capex': 'capital expenditure',\n",
    "            'opex': 'operating expense',\n",
    "            'r&d': 'research development',\n",
    "            'roi': 'return on investment',\n",
    "            'roic': 'return on invested capital',\n",
    "            'roa': 'return on assets',\n",
    "            'roe': 'return on equity'\n",
    "        }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Guardado del Corpus Procesado\n",
    "\n",
    "- Cada documento procesado se convierte en una fila del CSV con su nombre y contenido procesado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convertimos los textos procesados en un formato adecuado\n",
    "processed_data = pd.DataFrame({\n",
    "    'file_name': [doc['file_name'] for doc in documents],\n",
    "    'processed_content': [' '.join(preprocess_document(doc['content'])) for doc in documents]\n",
    "})\n",
    "\n",
    "# Guardamos el archivo\n",
    "processed_data.to_csv('processed_documents.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Guardado de Estadísticas del Preprocesamiento\n",
    "- Después de realizar todas las etapas de preprocesamiento se almacenan las estadísticas obtenidas para facilitar la evaluación posterior del sistema.\n",
    "\n",
    "Estadísticas a guardar:\n",
    "\n",
    "* Número de documentos procesados.\n",
    "* Número de tokens procesados por documento.\n",
    "* Número de tokens únicos (vocabulario total).\n",
    "* Promedio de tokens por documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_preprocessing_statistics(processed_docs: list, output_path: str):\n",
    "    \"\"\"\n",
    "    Guarda las estadísticas del preprocesamiento de los documentos.\n",
    "    Args:\n",
    "        processed_docs (list): Lista de documentos procesados.\n",
    "        output_path (str): Ruta donde se guardarán las estadísticas.\n",
    "    \"\"\"\n",
    "    # Estadísticas de los documentos\n",
    "    num_documents = len(processed_docs)\n",
    "    total_tokens = sum([len(doc.split()) for doc in processed_docs])\n",
    "    unique_tokens = len(set(\" \".join(processed_docs).split()))\n",
    "    avg_tokens_per_doc = total_tokens / num_documents if num_documents > 0 else 0\n",
    "\n",
    "    stats = {\n",
    "        'Número de Documentos': num_documents,\n",
    "        'Tokens Totales': total_tokens,\n",
    "        'Tokens Únicos': unique_tokens,\n",
    "        'Promedio de Tokens por Documento': avg_tokens_per_doc\n",
    "    }\n",
    "\n",
    "    # Convertir estadísticas en un DataFrame\n",
    "    stats_df = pd.DataFrame([stats])\n",
    "\n",
    "    # Guardar estadísticas en archivo CSV\n",
    "    stats_df.to_csv(output_path, index=False)\n",
    "    print(f\"Estadísticas del preprocesamiento guardadas en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Representacióon de Datos en Espacio Vectorial\n",
    "\n",
    "\n",
    "Esta fase consiste en transformar los documentos del corpus en matrices numéricas que los algoritmos pueden procesar para medir similitudes y realizar búsquedas eficaces. Además, se guarda esta información en un archivo CSV para su reutilización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Carga de Datos Preprocesados\n",
    "\n",
    "- Se cargan los datos preprocesados desde un archivo CSV\n",
    "- Este archivo contiene el ID del documento, su título y el contenido procesado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos preprocesados\n",
    "processed_data = pd.read_csv('reuters_preprocessed_clean.csv')\n",
    "\n",
    "# Asegurar que las columnas tienen el formato correcto\n",
    "processed_data['id'] = processed_data['id'].astype(str)\n",
    "processed_data['body'] = processed_data['body'].astype(str)\n",
    "\n",
    "# Extraer el texto procesado para vectorización\n",
    "processed_texts = processed_data['body'].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Inicialización de Métodos de Vectorización\n",
    "\n",
    "- Antes de aplicar cualquier técnica, se inicializan los métodos necesarios para generar las representaciones vectoriales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Configurar vectorizadores BoW y TF-IDF\n",
    "bow_vectorizer = CountVectorizer(min_df=2, max_df=0.95)\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=2, max_df=0.95)\n",
    "\n",
    "# Cargar modelo preentrenado Word2Vec\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "# Inicializamos los vectorizadores\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "bow_vectorizer = CountVectorizer()\n",
    "binary_vectorizer = CountVectorizer(binary=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Vectorización con TF-IDF\n",
    "\n",
    "- Se genera la representación TF-IDF, asignando pesos a términos en función de su frecuencia relativa.\n",
    "\n",
    "Cálculo de Estadísticas:\n",
    "- Tamaño del vocabulario: Palabras únicas generadas.\n",
    "- Valores de IDF: Medida de la importancia de los términos en el corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar matriz TF-IDF\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(processed_texts)\n",
    "\n",
    "# Calcular estadísticas\n",
    "tfidf_stats = {\n",
    "    'matrix_shape': tfidf_matrix.shape,\n",
    "    'vocabulary_size': len(tfidf_vectorizer.vocabulary_),\n",
    "    'sparsity': 1.0 - (tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1]))\n",
    "}\n",
    "\n",
    "# Generar estadísticas detalladas\n",
    "tfidf_statistics = pd.DataFrame({\n",
    "    'term': tfidf_vectorizer.get_feature_names_out(),\n",
    "    'idf': tfidf_vectorizer.idf_\n",
    "})\n",
    "tfidf_statistics.to_csv('tfidf_statistics.csv', index=False)\n",
    "print(\"Estadísticas TF-IDF guardadas en: tfidf_statistics.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Vectorización con BoW \n",
    "\n",
    "- Se genera una matriz dispersa donde cada fila representa un documento y cada columna, un término del vocabulario.\n",
    "\n",
    "Cálculo de Estadísticas:\n",
    "* Tamaño de la matriz: Número de documentos x número de términos únicos.\n",
    "* Sparsidad: Proporción de ceros en la matriz, indicando qué tan dispersa es.\n",
    "* Tamaño del vocabulario: Número total de términos únicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar BoW\n",
    "bow_matrix = bow_vectorizer.fit_transform(processed_texts)\n",
    "\n",
    "# Generar matriz BoW\n",
    "bow_matrix = bow_vectorizer.fit_transform(processed_texts)\n",
    "\n",
    "# Calcular estadísticas\n",
    "bow_stats = {\n",
    "    'matrix_shape': bow_matrix.shape,\n",
    "    'vocabulary_size': len(bow_vectorizer.vocabulary_),\n",
    "    'sparsity': 1.0 - (bow_matrix.nnz / (bow_matrix.shape[0] * bow_matrix.shape[1]))\n",
    "}\n",
    "\n",
    "# Guardar estadísticas detalladas\n",
    "import pandas as pd\n",
    "\n",
    "bow_statistics = pd.DataFrame({\n",
    "    'term': bow_vectorizer.get_feature_names_out(),\n",
    "    'frequency': bow_matrix.sum(axis=0).tolist()[0]\n",
    "})\n",
    "bow_statistics.to_csv('bow_statistics.csv', index=False)\n",
    "print(\"Estadísticas BoW guardadas en: bow_statistics.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Vectorización con Word2Vec\n",
    "\n",
    "- Word2Vec genera vectores denso sutilizando un modelo preentrenado que captura relaciones semánticas entre palabras.\n",
    "\n",
    "Cálculo de Estadísticas:\n",
    "* Cobertura del vocabulario: Proporción de palabras del corpus presentes en el modelo preentrenado.\n",
    "* Dimensiones del vector: Longitud del vector generado para cada documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Generar vectores promedio para cada documento\n",
    "vector_size = word2vec_model.vector_size\n",
    "doc_vectors = []\n",
    "words_found = 0\n",
    "total_words = 0\n",
    "\n",
    "for doc in processed_texts:\n",
    "    words = simple_preprocess(doc)\n",
    "    total_words += len(words)\n",
    "    \n",
    "    vec = np.zeros(vector_size)\n",
    "    count = 0\n",
    "    \n",
    "    for word in words:\n",
    "        if word in word2vec_model:\n",
    "            vec += word2vec_model[word]\n",
    "            count += 1\n",
    "            words_found += 1\n",
    "    \n",
    "    if count > 0:\n",
    "        vec /= count\n",
    "    doc_vectors.append(vec)\n",
    "\n",
    "# Matriz resultante\n",
    "word2vec_matrix = np.vstack(doc_vectors)\n",
    "\n",
    "# Calcular estadísticas\n",
    "word2vec_stats = {\n",
    "    'matrix_shape': word2vec_matrix.shape,\n",
    "    'vocabulary_coverage': (words_found / total_words) * 100\n",
    "}\n",
    "\n",
    "# Guardar estadísticas\n",
    "word2vec_stats_df = pd.DataFrame([word2vec_stats])\n",
    "word2vec_stats_df.to_csv('word2vec_statistics.csv', index=False)\n",
    "print(\"Estadísticas Word2Vec guardadas en: word2vec_statistics.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Consolidación de Estadísticas de Vectorización\n",
    "\n",
    "Todas las estadísticas generadas se consolidan en un único archivo para comparar los métodos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidar estadísticas\n",
    "vectorization_summary = pd.DataFrame([\n",
    "    {'Método': 'BoW', 'Términos Únicos': len(bow_statistics), 'Archivo': 'bow_statistics.csv'},\n",
    "    {'Método': 'TF-IDF', 'Términos Únicos': len(tfidf_statistics), 'Archivo': 'tfidf_statistics.csv'},\n",
    "    {'Método': 'Word2Vec', 'Dimensiones del Vector': vector_size, 'Cobertura del Vocabulario (%)': vocab_coverage, 'Archivo': 'word2vec_statistics.csv'}\n",
    "])\n",
    "\n",
    "# Guardar resumen consolidado\n",
    "vectorization_summary.to_csv('vectorization_summary.csv', index=False)\n",
    "print(\"Resumen de vectorización guardado en: vectorization_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Evaluación de los Métodos de Vectorización\n",
    "\n",
    "Para evaluar los métodos, se compararon métricas clave como precisión, recall y tiempo de cálculo. Estas métricas se calculan tras realizar búsquedas en el corpus usando cada técnica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_vectorization(vectorizer, queries, corpus_matrix):\n",
    "    \"\"\"\n",
    "    Evalúa un método de vectorización utilizando métricas de recuperación.\n",
    "    Args:\n",
    "        vectorizer: Vectorizador (e.g., TF-IDF, BoW, Word2Vec).\n",
    "        queries: Lista de consultas de prueba.\n",
    "        corpus_matrix: Matriz de documentos vectorizados.\n",
    "    Returns:\n",
    "        Dict: Métricas de evaluación.\n",
    "    \"\"\"\n",
    "    metrics = {'precision': [], 'recall': [], 'f1_score': []}\n",
    "    for query in queries:\n",
    "        query_vector = vectorizer.transform([query])\n",
    "        results = cosine_similarity(query_vector, corpus_matrix)\n",
    "        # Aquí se calcularían las métricas con base en los resultados obtenidos\n",
    "        precision, recall, f1 = calculate_metrics(results)\n",
    "        metrics['precision'].append(precision)\n",
    "        metrics['recall'].append(recall)\n",
    "        metrics['f1_score'].append(f1)\n",
    "    \n",
    "    # Promedio de las métricas\n",
    "    avg_metrics = {k: np.mean(v) for k, v in metrics.items()}\n",
    "    return avg_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Selección de la Representación\n",
    "\n",
    "- Una vez generadas las matrices, se selecciona el método vectorial a utilizar según el objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_matrix = tfidf_matrix  # Cambiar a bow_matrix o binary_matrix según el caso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Indexación\n",
    "\n",
    "El índice invertido organiza las palabras del corpus junto con los documentos en los que aparecen. Esto permite búsquedas rápidas al localizar documentos relevantes directamente a partir de los términos de consulta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Estructura del índice\n",
    "\n",
    "El índice es implementado como un diccionario donde cada término tiene como valor una lista de identificadores de documentos.\n",
    "\n",
    "- La clase InvertedIndex usa un diccionario de Python para almacenar el índice, donde cada término apunta a un conjunto de documentos en los que aparece.\n",
    "- El método add_document agrega los términos de un documento a este índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "class InvertedIndex:\n",
    "    def __init__(self):\n",
    "        # Usamos defaultdict para facilitar la creación de listas automáticamente\n",
    "        self.index = defaultdict(set)  # Mapea términos a un conjunto de doc_ids\n",
    "\n",
    "    def add_document(self, doc_id: str, terms: list):\n",
    "        \"\"\"\n",
    "        Añade los términos de un documento al índice invertido.\n",
    "        \n",
    "        Args:\n",
    "            doc_id (str): Identificador único del documento.\n",
    "            terms (list): Lista de términos del documento.\n",
    "        \"\"\"\n",
    "        for term in terms:\n",
    "            self.index[term].add(doc_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Carga del Corpus y Construcción del Índice Invertido\n",
    "\n",
    "Se recorren todos los documentos preprocesados para añadirlos al índice.\n",
    "\n",
    "- La función build_inverted_index recorre una lista de documentos, procesando su contenido y añadiendo los términos al índice invertido usando la clase InvertedIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inverted_index(processed_data: pd.DataFrame) -> InvertedIndex:\n",
    "    \"\"\"\n",
    "    Construye el índice invertido a partir de los documentos procesados.\n",
    "\n",
    "    Args:\n",
    "        processed_data (pd.DataFrame): DataFrame que contiene los documentos preprocesados.\n",
    "        \n",
    "    Returns:\n",
    "        InvertedIndex: El índice invertido que contiene los términos mapeados a los documentos.\n",
    "    \"\"\"\n",
    "    index = InvertedIndex()\n",
    "    \n",
    "    for index, row in processed_data.iterrows():\n",
    "        doc_id = row['id']\n",
    "        content = row['body']\n",
    "        terms = preprocess_document(content)  # Utilizamos el preprocesamiento de los textos\n",
    "        index.add_document(doc_id, terms)\n",
    "    \n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Guardado del Índice Invertido\n",
    "\n",
    "- El índice invertido debe guardarse en un archivo CSV para su posterior recuperación y uso en la búsqueda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_inverted_index(index: InvertedIndex, output_file: str):\n",
    "    \"\"\"\n",
    "    Guarda el índice invertido en un archivo CSV.\n",
    "    \n",
    "    Args:\n",
    "        index (InvertedIndex): El índice invertido a guardar.\n",
    "        output_file (str): Ruta al archivo donde se guardará el índice.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['term', 'doc_ids'])  # Cabeceras\n",
    "        for term, doc_ids in index.index.items():\n",
    "            writer.writerow([term, \" \".join(doc_ids)])  # Convertimos doc_ids a string\n",
    "    print(f\"Índice invertido guardado en: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Mecanismo de búsqueda \n",
    "\n",
    "La búsqueda se realiza comparando la consulta del usuario con los documentos preprocesados y vectorizados. La similitud del coseno es la métrica utilizada para determinar qué tan similares son dos vectores en el espacio de características.\n",
    "\n",
    "- Flujo del Motor de Búsqueda:\n",
    "\n",
    "1.Ingreso de la Consulta → 2. Preprocesamiento → 3. Vectorización → 4. Cálculo de Similitud → 5. Ranking → 6. Recuperación → 7. Salida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Procesamiento de la Consulta\n",
    "\n",
    "- La consulta del usuario se preprocesa para convertirla en un formato que pueda ser comparado con los documentos del corpus.\n",
    "-  El procesamiento de la consulta sigue los mismos pasos que se aplicaron a los documentos en el corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query(query: str) -> list:\n",
    "    \"\"\"\n",
    "    Preprocesa la consulta del usuario (tokenización, eliminación de stopwords, lematización).\n",
    "    \n",
    "    Args:\n",
    "        query (str): La consulta introducida por el usuario.\n",
    "    \n",
    "    Returns:\n",
    "        list: Lista de tokens procesados.\n",
    "    \"\"\"\n",
    "    query_tokens = preprocess_document(query)  # Usamos el preprocesamiento ya definido\n",
    "    return query_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Transformación de la Consulta en Vector\n",
    "- Una vez procesada la consulta, se transforma en un vector utilizando el mismo vectorizador que se usó para los documentos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamos la consulta\n",
    "query_tokens = preprocess_query(query)  # Tokenización y limpieza\n",
    "query_vec = vectorizer.transform([' '.join(query_tokens)])  # Transformar la consulta en vector utilizando el vectorizador\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Cálculo de la Similitud  Coseno entre la Consulta y los Documentos\n",
    "\n",
    "- Después de que la consulta se ha convertido en un vector, el siguiente paso es calcular su similitud con cada uno de los documentos en el corpus. Utilizamos la similitud coseno, que mide el ángulo entre los vectores de la consulta y los documentos. \n",
    "\n",
    "- Utilizamos la función de scikit-learn para calcular la similitud coseno entre el vector de la consulta y la matriz de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_cosine_similarity(query_vector, document_matrix):\n",
    "    \"\"\"\n",
    "    Calcula la similitud coseno entre la consulta y los documentos.\n",
    "    \n",
    "    Args:\n",
    "        query_vector (sparse matrix): Vector de la consulta procesada.\n",
    "        document_matrix (sparse matrix): Matriz de los documentos preprocesados (BoW o TF-IDF).\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Similitudes entre la consulta y los documentos.\n",
    "    \"\"\"\n",
    "    return cosine_similarity(query_vector, document_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Ranking de los Resultados\n",
    "\n",
    "- Una vez calculadas las similitudes, necesitamos ordenar los documentos de acuerdo con su relevancia.\n",
    "- El ranking se hace ordenando las similitudes de mayor a menor, para devolver los documentos más relevantes en la parte superior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rank_documents(similarities, top_k=5):\n",
    "    \"\"\"\n",
    "    Ordena los documentos según su similitud con la consulta y devuelve los primeros `k` documentos.\n",
    "    \n",
    "    Args:\n",
    "        similarities (np.ndarray): Array de similitudes entre la consulta y los documentos.\n",
    "        top_k (int): Número máximo de resultados a retornar.\n",
    "    \n",
    "    Returns:\n",
    "        list: Lista de índices de documentos ordenados por relevancia.\n",
    "    \"\"\"\n",
    "    sorted_indices = np.argsort(similarities)[::-1][:top_k]  # Ordenar y seleccionar top_k\n",
    "    return sorted_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Recuperación de los Documentos Relevantes\n",
    "\n",
    "- Después de ordenar los documentos por similitud, se recuperan los top_k documentos más relevantes. Esta función extrae la información de los documentos (título, cuerpo y score) para mostrarlos al usuario.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(sorted_indices, corpus_df):\n",
    "    \"\"\"\n",
    "    Recupera los documentos relevantes del corpus basándose en los índices ordenados.\n",
    "    \n",
    "    Args:\n",
    "        sorted_indices (list): Índices de los documentos ordenados por similitud.\n",
    "        corpus_df (pd.DataFrame): DataFrame con el corpus de documentos.\n",
    "    \n",
    "    Returns:\n",
    "        list: Lista de documentos relevantes.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for idx in sorted_indices:\n",
    "        doc_info = corpus_df.iloc[idx]\n",
    "        results.append({\n",
    "            'id': doc_info['id'],\n",
    "            'title': doc_info['title'],\n",
    "            'body': doc_info['body'][:200] + '...',  # Primeros 200 caracteres\n",
    "            'score': float(similarities[idx])\n",
    "        })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.  Motor de Búsqueda Completo\n",
    "\n",
    "El método principal del motor de búsqueda:\n",
    "1. Preprocesa la consulta.\n",
    "2. La convierte en un vector utilizando el vectorizador.\n",
    "3. Calcula las similitudes con la matriz de documentos.\n",
    "4. Ordena los documentos por relevancia.\n",
    "5. Recupera y devuelve los top_k documentos más relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchEngine:\n",
    "    def __init__(self, corpus_df, vectorizer):\n",
    "        self.corpus_df = corpus_df\n",
    "        self.vectorizer = vectorizer\n",
    "        self.document_matrix = vectorizer.transform(corpus_df['body'])\n",
    "    \n",
    "    def search(self, query, top_k=5):\n",
    "        # Preprocesamos la consulta\n",
    "        query_tokens = preprocess_query(query)  # Preprocesamiento de la consulta\n",
    "        query_vec = self.vectorizer.transform([' '.join(query_tokens)])  # Transformar la consulta en vector\n",
    "\n",
    "        # Calculamos la similitud\n",
    "        similarities = calculate_cosine_similarity(query_vec, self.document_matrix)  # Similitud coseno\n",
    "        sorted_indices = rank_documents(similarities.flatten(), top_k)  # Ranking de resultados\n",
    "\n",
    "        # Recuperamos los documentos más relevantes\n",
    "        return retrieve_documents(sorted_indices, self.corpus_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.Evaluación del Sistema\n",
    "\n",
    "Se utilizan métricas estándar como precisión, recall, F1-score y mean average precision (MAP) para evaluar el desempeño del sistema "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implementación de la Evaluación\n",
    "\n",
    "- Para evaluar el sistema, se utiliza un conjunto de consultas de prueba. Para cada consulta, se calculan las métricas de precisión, recall, F1-score, y MAP.\n",
    "- Posteriormente, se realiza una evaluación global del sistema utilizando estas métricas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_query(query: str, relevant_docs: str, k: int = 10) -> dict:\n",
    "    \"\"\"\n",
    "    Evalúa una consulta individual.\n",
    "    \n",
    "    Args:\n",
    "        query (str): La consulta del usuario.\n",
    "        relevant_docs (str): Documentos relevantes para la consulta.\n",
    "        k (int): Número de resultados a considerar.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Diccionario con métricas de la consulta.\n",
    "    \"\"\"\n",
    "    relevant_set = set(relevant_docs.split())  # Convertimos los documentos relevantes en un set\n",
    "    search_results = search_engine.search(query, num_results=k)  # Realizamos la búsqueda\n",
    "    retrieved_set = {str(result['id']) for result in search_results}  # Convertimos los documentos recuperados en un set\n",
    "    \n",
    "    # Cálculo de precisión, recall y F1-score\n",
    "    relevant_retrieved = retrieved_set & relevant_set\n",
    "    precision = len(relevant_retrieved) / len(retrieved_set) if retrieved_set else 0\n",
    "    recall = len(relevant_retrieved) / len(relevant_set) if relevant_set else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    # Cálculo de MAP (Average Precision)\n",
    "    ap = calculate_average_precision(search_results, relevant_set)\n",
    "    \n",
    "    # Cálculo de nDCG (Normalized Discounted Cumulative Gain)\n",
    "    dcg = calculate_dcg(search_results, relevant_set, k)\n",
    "    idcg = calculate_idcg(len(relevant_set), k)\n",
    "    ndcg = dcg / idcg if idcg > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'average_precision': ap,\n",
    "        'ndcg': ndcg,\n",
    "        'retrieved_count': len(retrieved_set),\n",
    "        'relevant_count': len(relevant_set),\n",
    "        'relevant_retrieved_count': len(relevant_retrieved)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Cálculo del MAP\n",
    "\n",
    "- El método calculate_average_precision calcula la precisión promedio para una consulta al sumar las precisiones en cada posición del ranking de los documentos relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_precision(results: list, relevant_docs: set) -> float:\n",
    "    \"\"\"\n",
    "    Calcula la precisión promedio (AP) para una consulta.\n",
    "    \n",
    "    Args:\n",
    "        results (list): Resultados de la consulta.\n",
    "        relevant_docs (set): Conjunto de documentos relevantes para la consulta.\n",
    "    \n",
    "    Returns:\n",
    "        float: La precisión promedio.\n",
    "    \"\"\"\n",
    "    precision_sum = 0\n",
    "    relevant_found = 0\n",
    "    for i, result in enumerate(results, 1):\n",
    "        if str(result['id']) in relevant_docs:\n",
    "            relevant_found += 1\n",
    "            precision_at_k = relevant_found / i\n",
    "            precision_sum += precision_at_k\n",
    "    \n",
    "    return precision_sum / len(relevant_docs) if relevant_docs else 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Cálculo de nDCG\n",
    "\n",
    "- El método calculate_dcg calcula el DCG basado en la relevancia de los documentos. El DCG penaliza los documentos relevantes que están en posiciones más bajas de la lista de resultados, lo que refleja que es más importante que los documentos relevantes estén en las primeras posiciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dcg(results: list, relevant_docs: set, k: int) -> float:\n",
    "    \"\"\"\n",
    "    Calcula Discounted Cumulative Gain (DCG) para los primeros `k` resultados.\n",
    "    \n",
    "    Args:\n",
    "        results (list): Resultados de la búsqueda.\n",
    "        relevant_docs (set): Conjunto de documentos relevantes.\n",
    "        k (int): Número de resultados a considerar.\n",
    "    \n",
    "    Returns:\n",
    "        float: El valor de DCG.\n",
    "    \"\"\"\n",
    "    dcg = 0\n",
    "    for i, result in enumerate(results[:k], 1):\n",
    "        rel = 1 if str(result['id']) in relevant_docs else 0\n",
    "        dcg += rel / np.log2(i + 1)\n",
    "    return dcg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Evaluación del Sistema Completo\n",
    "\n",
    "- Se evalúa el rendimiento del sistema en su totalidad utilizando un conjunto de consultas de prueba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_system(test_queries: pd.DataFrame, k_values: list = [5, 10, 20]) -> dict:\n",
    "    \"\"\"\n",
    "    Evalúa el sistema completo para diferentes valores de k (top-k resultados).\n",
    "    \n",
    "    Args:\n",
    "        test_queries (pd.DataFrame): Conjunto de consultas de prueba.\n",
    "        k_values (list): Lista de valores de k para evaluar.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Resultados de la evaluación con las métricas para cada k.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        query_results = []\n",
    "        for _, row in tqdm(test_queries.iterrows(), total=len(test_queries)):\n",
    "            eval_result = evaluate_query(row['query'], row['relevant_docs'], k)\n",
    "            eval_result['query'] = row['query']\n",
    "            query_results.append(eval_result)\n",
    "        \n",
    "        avg_metrics = {\n",
    "            'avg_precision': np.mean([r['precision'] for r in query_results]),\n",
    "            'avg_recall': np.mean([r['recall'] for r in query_results]),\n",
    "            'avg_f1': np.mean([r['f1_score'] for r in query_results]),\n",
    "            'mean_ap': np.mean([r['average_precision'] for r in query_results]),\n",
    "            'avg_ndcg': np.mean([r['ndcg'] for r in query_results])\n",
    "        }\n",
    "        \n",
    "        results[k] = {\n",
    "            'query_results': query_results,\n",
    "            'average_metrics': avg_metrics\n",
    "        }\n",
    "        \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Guardado de los Resultados de Evaluación\n",
    "\n",
    "- Una vez que se calculan las métricas de evaluación para cada consulta y se obtiene un resumen global del sistema, es importante guardar estos resultados de forma organizada.\n",
    "\n",
    "- Los resultados los guardamos en dos formatos diferntes en un archivo JSON y un CSV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Archivo JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "def save_detailed_results(results: dict, output_dir: str = 'evaluation_results'):\n",
    "    \"\"\"\n",
    "    Guarda los resultados detallados de la evaluación en un archivo JSON.\n",
    "    \n",
    "    Args:\n",
    "        results (dict): Los resultados de la evaluación por consulta.\n",
    "        output_dir (str): Directorio donde se guardarán los resultados.\n",
    "    \"\"\"\n",
    "    # Crear el directorio de salida si no existe\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Generar un timestamp para nombrar el archivo\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Guardar los resultados detallados en formato JSON\n",
    "    with open(f'{output_dir}/detailed_results_{timestamp}.json', 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(f\"Resultados detallados guardados en: {output_dir}/detailed_results_{timestamp}.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Archivo CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_summary_results(results: dict, output_dir: str = 'evaluation_results'):\n",
    "    \"\"\"\n",
    "    Guarda los resultados agregados de la evaluación en un archivo CSV.\n",
    "    \n",
    "    Args:\n",
    "        results (dict): Los resultados de la evaluación por consulta.\n",
    "        output_dir (str): Directorio donde se guardarán los resultados.\n",
    "    \"\"\"\n",
    "    # Crear el directorio de salida si no existe\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Convertir los resultados agregados en un DataFrame\n",
    "    summary_data = []\n",
    "    for k, result in results.items():\n",
    "        summary_data.append({\n",
    "            'k': k,\n",
    "            'avg_precision': result['average_metrics']['avg_precision'],\n",
    "            'avg_recall': result['average_metrics']['avg_recall'],\n",
    "            'avg_f1': result['average_metrics']['avg_f1'],\n",
    "            'mean_ap': result['average_metrics']['mean_ap'],\n",
    "            'avg_ndcg': result['average_metrics']['avg_ndcg']\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Guardar los resultados agregados en un archivo CSV\n",
    "    summary_df.to_csv(f'{output_dir}/evaluation_summary.csv', index=False)\n",
    "    print(f\"Resultados agregados guardados en: {output_dir}/evaluation_summary.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
